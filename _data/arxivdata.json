{"0704.2241":{"title":"Why should anyone care about computing with anyons?","abstract":"In this article we present a pedagogical introduction of the main ideas and recent advances in the area of topological quantum computation. We give an overview of the concept of anyons and their exotic statistics, present various models that exhibit topological behavior, and we establish their relation to quantum computation. Possible directions for the physical realization of topological systems and the detection of anyonic behavior are elaborated.","authors":"Gavin K. Brennen, Jiannis K. Pachos"},"0708.1879":{"title":"Quantum random access memory","abstract":"A random access memory (RAM) uses n bits to randomly address N=2^n distinct memory cells. A quantum random access memory (qRAM) uses n qubits to address any quantum superposition of N memory cells. We present an architecture that exponentially reduces the requirements for a memory call: O(log N) switches need be thrown instead of the N used in conventional (classical or quantum) RAM designs. This yields a more robust qRAM algorithm, as it in general requires entanglement among exponentially less gates, and leads to an exponential decrease in the power needed for addressing. A quantum optical implementation is presented.","authors":"Vittorio Giovannetti, Seth Lloyd, Lorenzo Maccone"},"0906.4716":{"title":"Algebraic characterization of X-states in quantum information","abstract":"A class of two-qubit states called X-states are increasingly being used to discuss entanglement and other quantum correlations in the field of quantum information. Maximally entangled Bell states and \"Werner\" states are subsets of them. Apart from being so named because their density matrix looks like the letter X, there is not as yet any characterization of them. The su(2) X su(2) X u(1) subalgebra of the full su(4) algebra of two qubits is pointed out as the underlying invariance of this class of states. X-states are a seven-parameter family associated with this subalgebra of seven operators. This recognition provides a route to preparing such states and also a convenient algebraic procedure for analytically calculating their properties. At the same time, it points to other groups of seven-parameter states that, while not at first sight appearing similar, are also invariant under the same subalgebra. And it opens the way to analyzing invariant states of other subalgebras in bipartite systems.","authors":"A. R. P. Rau"},"1108.1791":{"title":"Why Philosophers Should Care About Computational Complexity","abstract":"One might think that, once we know something is computable, how efficiently it can be computed is a practical question with little further philosophical importance. In this essay, I offer a detailed case that one would be wrong. In particular, I argue that computational complexity theory---the field that studies the resources (such as time, space, and randomness) needed to solve computational problems---leads to new perspectives on the nature of mathematical knowledge, the strong AI debate, computationalism, the problem of logical omniscience, Hume's problem of induction, Goodman's grue riddle, the foundations of quantum mechanics, economic rationality, closed timelike curves, and several other topics of philosophical interest. I end by discussing aspects of complexity theory itself that could benefit from philosophical analysis.","authors":"Scott Aaronson"},"1305.3977":{"title":"Invariant Gaussian processes and independent sets on regular graphs of large girth","abstract":"We prove that every 3-regular, n-vertex simple graph with sufficiently large girth contains an independent set of size at least 0.4361n. (The best known bound is 0.4352n.) In fact, computer simulation suggests that the bound our method provides is about 0.438n. Our method uses invariant Gaussian processes on the d-regular tree that satisfy the eigenvector equation at each vertex for a certain eigenvalue \\lambda. We show that such processes can be approximated by i.i.d. factors provided that $|\\lambda| \\leq 2\\sqrt{d-1}$. We then use these approximations for $\\lambda = -2\\sqrt{d-1}$ to produce factor of i.i.d. independent sets on regular trees.","authors":"Endre Csóka, Balázs Gerencsér, Viktor Harangi, Bálint Virág"},"1308.0266":{"title":"Local algorithms, regular graphs of large girth, and random regular graphs","abstract":"We introduce a general class of algorithms and supply a number of general results useful for analysing these algorithms when applied to regular graphs of large girth. As a result, we can transfer a number of results proved for random regular graphs into (deterministic) results about all regular graphs with sufficiently large girth. This is an uncommon direction of transfer of results, which is usually from the deterministic setting to the random one. In particular, this approach enables, for the first time, the achievement of results equivalent to those obtained on random regular graphs by a powerful class of algorithms which contain prioritised actions. As examples, we obtain new upper or lower bounds on the size of maximum independent sets, minimum dominating sets, maximum and minimum bisection, maximum $k$-independent sets, minimum $k$-dominating sets and minimum connected and weakly-connected dominating sets in $r$-regular graphs with large girth.","authors":"Carlos Hoppen, Nicholas Wormald"},"1401.4197":{"title":"Factors of IID on Trees","abstract":"Classical ergodic theory for integer-group actions uses entropy as a complete invariant for isomorphism of IID (independent, identically distributed) processes (a.k.a. product measures). This theory holds for amenable groups as well. Despite recent spectacular progress of Bowen, the situation for non-amenable groups, including free groups, is still largely mysterious. We present some illustrative results and open questions on free groups, which are particularly interesting in combinatorics, statistical physics, and probability. Our results include bounds on minimum and maximum bisection for random cubic graphs that improve on all past bounds.","authors":"Russell Lyons"},"1408.5593":{"title":"Event-by-event simulation of a quantum delayed-choice experiment","abstract":"The quantum delayed-choice experiment of Tang et al. [Nature Photonics 6 (2012) 600] is simulated on the level of individual events without making reference to concepts of quantum theory or without solving a wave equation. The simulation results are in excellent agreement with the quantum theoretical predictions of this experiment. The implication of the work presented in the present paper is that the experiment of Tang et al. can be explained in terms of cause-and-effect processes in an event-by-event manner.","authors":"Hylke C. Donker, Hans De Raedt, Kristel Michielsen"},"1412.8427":{"title":"Boson Sampling for Molecular Vibronic Spectra","abstract":"Quantum computers are expected to be more efficient in performing certain computations than any classical machine. Unfortunately, the technological challenges associated with building a full-scale quantum computer have not yet allowed the experimental verification of such an expectation. Recently, boson sampling has emerged as a problem that is suspected to be intractable on any classical computer, but efficiently implementable with a linear quantum optical setup. Therefore, boson sampling may offer an experimentally realizable challenge to the Extended Church-Turing thesis and this remarkable possibility motivated much of the interest around boson sampling, at least in relation to complexity-theoretic questions. In this work, we show that the successful development of a boson sampling apparatus would not only answer such inquiries, but also yield a practical tool for difficult molecular computations. Specifically, we show that a boson sampling device with a modified input state can be used to generate molecular vibronic spectra, including complicated effects such as Duschinsky rotations.","authors":"Joonsuk Huh, Gian Giacomo Guerreschi, Borja Peropadre, Jarrod R. McClean, Alán Aspuru-Guzik"},"1502.04398":{"title":"A Dynamic Programming Approach to the Parisi Functional","abstract":"G.Parisi predicted an important variational formula for the thermodynamic limit of the intensive free energy for a class of mean field spin glasses. In this paper, we present an elementary approach to the study of the Parisi functional using stochastic dynamic programing and semi-linear PDE. We give a derivation of important properties of the Parisi PDE avoiding the use of Ruelle Probability Cascades and Cole-Hopf transformations. As an application, we give a simple proof of the strict convexity of the Parisi functional, which was recently proved by Auffinger and Chen in [2].","authors":"Aukosh Jagannath, Ian Tobasco"},"1503.03923":{"title":"Extremal Cuts of Sparse Random Graphs","abstract":"For Erd\\H{o}s-R\\'enyi random graphs with average degree $\\gamma$, and uniformly random $\\gamma$-regular graph on $n$ vertices, we prove that with high probability the size of both the Max-Cut and maximum bisection are $n\\Big(\\frac{\\gamma}{4} + {{\\sf P}}_* \\sqrt{\\frac{\\gamma}{4}} + o(\\sqrt{\\gamma})\\Big) + o(n)$ while the size of the minimum bisection is $n\\Big(\\frac{\\gamma}{4}-{{\\sf P}}_*\\sqrt{\\frac{\\gamma}{4}} + o(\\sqrt{\\gamma})\\Big) + o(n)$. Our derivation relates the free energy of the anti-ferromagnetic Ising model on such graphs to that of the Sherrington-Kirkpatrick model, with ${{\\sf P}}_* \\approx 0.7632$ standing for the ground state energy of the latter, expressed analytically via Parisi's formula.","authors":"Amir Dembo, Andrea Montanari, Subhabrata Sen"},"1509.08435":{"title":"Efficient long distance quantum communication","abstract":"Despite the tremendous progress of quantum cryptography, efficient quantum communication over long distances (&gt;1000km) remains an outstanding challenge due to fiber attenuation and operation errors accumulated over the entire communication distance. Quantum repeaters, as a promising approach, can overcome both photon loss and operation errors, and hence significantly speedup the communication rate. Depending on the methods used to correct loss and operation errors, all the proposed QR schemes can be classified into three categories (generations). Here we present the first systematic comparison of three generations of quantum repeaters by evaluating the cost of both temporal and physical resources, and identify the optimized quantum repeater architecture for a given set of experimental parameters. Our work provides a roadmap for the experimental realizations of highly efficient quantum networks over transcontinental distances.","authors":"Sreraman Muralidharan, Linshu Li, Jungsang Kim, Norbert Lütkenhaus, Mikhail D. Lukin, Liang Jiang"},"1602.07674":{"title":"Quantum Supremacy through the Quantum Approximate Optimization Algorithm","abstract":"The Quantum Approximate Optimization Algorithm (QAOA) is designed to run on a gate model quantum computer and has shallow depth. It takes as input a combinatorial optimization problem and outputs a string that satisfies a high fraction of the maximum number of clauses that can be satisfied. For certain problems the lowest depth version of the QAOA has provable performance guarantees although there exist classical algorithms that have better guarantees. Here we argue that beyond its possible computational value the QAOA can exhibit a form of Quantum Supremacy in that, based on reasonable complexity theoretic assumptions, the output distribution of even the lowest depth version cannot be efficiently simulated on any classical device. We contrast this with the case of sampling from the output of a quantum computer running the Quantum Adiabatic Algorithm (QADI) with the restriction that the Hamiltonian that governs the evolution is gapped and stoquastic. Here we show that there is an oracle that would allow sampling from the QADI but even with this oracle, if one could efficiently classically sample from the output of the QAOA, the Polynomial Hierarchy would collapse. This suggests that the QAOA is an excellent candidate to run on near term quantum computers not only because it may be of use for optimization but also because of its potential as a route to establishing quantum supremacy.","authors":"Edward Farhi, Aram W Harrow"},"1604.01384":{"title":"A Complete Characterization of Unitary Quantum Space","abstract":"Motivated by understanding the power of quantum computation with restricted number of qubits, we give two complete characterizations of unitary quantum space bounded computation. First we show that approximating an element of the inverse of a well-conditioned efficiently encoded $2^{k(n)}\\times 2^{k(n)}$ matrix is complete for the class of problems solvable by quantum circuits acting on $\\mathcal{O}(k(n))$ qubits with all measurements at the end of the computation. Similarly, estimating the minimum eigenvalue of an efficiently encoded Hermitian $2^{k(n)}\\times 2^{k(n)}$ matrix is also complete for this class. In the logspace case, our results improve on previous results of Ta-Shma [STOC '13] by giving new space-efficient quantum algorithms that avoid intermediate measurements, as well as showing matching hardness results. Additionally, as a consequence we show that PreciseQMA, the version of QMA with exponentially small completeness-soundess gap, is equal to PSPACE. Thus, the problem of estimating the minimum eigenvalue of a local Hamiltonian to inverse exponential precision is PSPACE-complete, which we show holds even in the frustration-free case. Finally, we can use this characterization to give a provable setting in which the ability to prepare the ground state of a local Hamiltonian is more powerful than the ability to prepare PEPS states. Interestingly, by suitably changing the parameterization of either of these problems we can completely characterize the power of quantum computation with simultaneously bounded time and space.","authors":"Bill Fefferman, Cedric Yen-Yu Lin"},"1707.03429":{"title":"Open Quantum Assembly Language","abstract":"This document describes a quantum assembly language (QASM) called OpenQASM that is used to implement experiments with low depth quantum circuits. OpenQASM represents universal physical circuits over the CNOT plus SU(2) basis with straight-line code that includes measurement, reset, fast feedback, and gate subroutines. The simple text language can be written by hand or by higher level tools and may be executed on the IBM Q Experience.","authors":"Andrew W. Cross, Lev S. Bishop, John A. Smolin, Jay M. Gambetta"},"1707.05386":{"title":"Suboptimality of local algorithms for a class of max-cut problems","abstract":"We show that in random $K$-uniform hypergraphs of constant average degree, for even $K \\geq 4$, local algorithms defined as factors of i.i.d. can not find nearly maximal cuts, when the average degree is sufficiently large. These algorithms have been used frequently to obtain lower bounds for the max-cut problem on random graphs, but it was not known whether they could be successful in finding nearly maximal cuts. This result follows from the fact that the overlap of any two nearly maximal cuts in such hypergraphs does not take values in a certain non-trivial interval - a phenomenon referred to as the overlap gap property - which is proved by comparing diluted models with large average degree with appropriate fully connected spin glass models and showing the overlap gap property in the latter setting.","authors":"Wei-Kuo Chen, David Gamarnik, Dmitry Panchenko, Mustazee Rahman"},"1802.07744":{"title":"Contextuality bounds the efficiency of classical simulation of quantum processes","abstract":"Contextuality has been conjectured to be a super-classical resource for quantum computation, analogous to the role of non-locality as a super-classical resource for communication. We show that the presence of contextuality places a lower bound on the amount of classical memory required to simulate any quantum sub-theory, thereby establishing a quantitative connection between contextuality and classical simulability. We apply our result to the qubit stabilizer sub-theory, where the presence of state-independent contextuality has been an obstacle in establishing contextuality as a quantum computational resource. We find that the presence of contextuality in this sub-theory demands that the minimum number of classical bits of memory required to simulate a multi-qubit system must scale quadratically in the number of qubits; notably, this is the same scaling as the Gottesman-Knill algorithm. We contrast this result with the (non-contextual) qudit case, where linear scaling is possible.","authors":"Angela Karanjai, Joel J. Wallman, Stephen D. Bartlett"},"1803.02176":{"title":"Quantum Walks via Quantum Cellular Automata","abstract":"Very much as its classical counterpart, quantum cellular automata are expected to be a great tool for simulating complex quantum systems. Here we introduce a partitioned model of quantum cellular automata and show how it can simulate, with the same amount of resources (in terms of effective Hilbert space dimension), various models of quantum walks. All the algorithms developed within quantum walk models are thus directly inherited by the quantum cellular automata. The latter, however, has its structure based on local interactions between qubits, and as such it can be more suitable for present (and future) experimental implementations.","authors":"Pedro C. S. Costa, Renato Portugal, Fernando de Melo"},"1804.09130":{"title":"On the representation of Boolean and real functions as Hamiltonians for quantum computing","abstract":"Mapping functions on bits to Hamiltonians acting on qubits has many applications in quantum computing. In particular, Hamiltonians representing Boolean functions are required for applications of quantum annealing or the quantum approximate optimization algorithm to combinatorial optimization problems. We show how such functions are naturally represented by Hamiltonians given as sums of Pauli $Z$ operators (Ising spin operators) with the terms of the sum corresponding to the function's Fourier expansion. For many classes of functions which are given by a compact description, such as a Boolean formula in conjunctive normal form that gives an instance of the satisfiability problem, it is #P-hard to compute its Hamiltonian representation. On the other hand, no such difficulty exists generally for constructing Hamiltonians representing a real function such as a sum of local Boolean clauses. We give composition rules for explicitly constructing Hamiltonians representing a wide variety of Boolean and real functions by combining Hamiltonians representing simpler clauses as building blocks. We apply our results to the construction of controlled-unitary operators, and to the special case of operators that compute function values in an ancilla qubit register. Finally, we outline several additional applications and extensions of our results. A primary goal of this paper is to provide a $\\textit{design toolkit for quantum optimization}$ which may be utilized by experts and practitioners alike in the construction and analysis of new quantum algorithms, and at the same time to demystify the various constructions appearing in the literature.","authors":"Stuart Hadfield"},"1805.03265":{"title":"Quantum Algorithms for Scientific Computing and Approximate Optimization","abstract":"Quantum computation appears to offer significant advantages over classical computation and this has generated a tremendous interest in the field. In this thesis we consider the application of quantum computers to scientific computing and combinatorial optimization. We study five problems. The first three deal with quantum algorithms for computational problems in science and engineering, including quantum simulation of physical systems. In particular, we study quantum algorithms for numerical computation, for the approximation of ground and excited state energies of the Schr\\\"odinger equation, and for Hamiltonian simulation with applications to physics and chemistry. The remaining two deal with quantum algorithms for approximate optimization. We study the performance of the quantum approximate optimization algorithm (QAOA), and show a generalization of QAOA, the $\\textit{quantum}$ $\\textit{alternating}$ $\\textit{operator}$ $\\textit{ansatz}$, particularly suitable for constrained optimization problems and low-resource implementations on near-term quantum devices.","authors":"Stuart Hadfield"},"1806.01838":{"title":"Quantum singular value transformation and beyond: exponential improvements for quantum matrix arithmetics","abstract":"Quantum computing is powerful because unitary operators describing the time-evolution of a quantum system have exponential size in terms of the number of qubits present in the system. We develop a new \"Singular value transformation\" algorithm capable of harnessing this exponential advantage, that can apply polynomial transformations to the singular values of a block of a unitary, generalizing the optimal Hamiltonian simulation results of Low and Chuang. The proposed quantum circuits have a very simple structure, often give rise to optimal algorithms and have appealing constant factors, while usually only use a constant number of ancilla qubits. We show that singular value transformation leads to novel algorithms. We give an efficient solution to a certain \"non-commutative\" measurement problem and propose a new method for singular value estimation. We also show how to exponentially improve the complexity of implementing fractional queries to unitaries with a gapped spectrum. Finally, as a quantum machine learning application we show how to efficiently implement principal component regression. \"Singular value transformation\" is conceptually simple and efficient, and leads to a unified framework of quantum algorithms incorporating a variety of quantum speed-ups. We illustrate this by showing how it generalizes a number of prominent quantum algorithms, including: optimal Hamiltonian simulation, implementing the Moore-Penrose pseudoinverse with exponential precision, fixed-point amplitude amplification, robust oblivious amplitude amplification, fast QMA amplification, fast quantum OR lemma, certain quantum walk results and several quantum machine learning algorithms. In order to exploit the strengths of the presented method it is useful to know its limitations too, therefore we also prove a lower bound on the efficiency of singular value transformation, which often gives optimal bounds.","authors":"András Gilyén, Yuan Su, Guang Hao Low, Nathan Wiebe"},"1810.07690":{"title":"Forecasting financial crashes with quantum computing","abstract":"A key problem in financial mathematics is the forecasting of financial crashes: if we perturb asset prices, will financial institutions fail on a massive scale? This was recently shown to be a computationally intractable (NP-hard) problem. Financial crashes are inherently difficult to predict, even for a regulator which has complete information about the financial system. In this paper we show how this problem can be handled by quantum annealers. More specifically, we map the equilibrium condition of a toy-model financial network to the ground-state problem of a spin-1/2 quantum Hamiltonian with 2-body interactions, i.e., a quadratic unconstrained binary optimization (QUBO) problem. The equilibrium market values of institutions after a sudden shock to the network can then be calculated via adiabatic quantum computation and, more generically, by quantum annealers. Our procedure could be implemented on near-term quantum processors, thus providing a potentially more efficient way to assess financial equilibrium and predict financial crashes.","authors":"Roman Orus, Samuel Mugel, Enrique Lizaso"},"1811.06657":{"title":"Time crystals in periodically driven systems","abstract":"When the discrete time-translation symmetry of isolated, periodically driven systems is spontaneously broken, a new phase of matter can emerge. We review some recent developments on both the theoretical underpinnings and experimental realizations of time crystalline order. Particular attention is placed on delineating the key features of time crystals, which distinguish them from other oscillatory non-equilibrium phenomena.","authors":"Norman Y. Yao, Chetan Nayak"},"1811.08017":{"title":"A random compiler for fast Hamiltonian simulation","abstract":"The dynamics of a quantum system can be simulated using a quantum computer by breaking down the unitary into a quantum circuit of one and two qubit gates. The most established methods are the Trotter-Suzuki decompositions, for which rigorous bounds on the circuit size depend on the number of terms $L$ in the system Hamiltonian and the size of the largest term in the Hamiltonian $\\Lambda$. Consequently, Trotter-Suzuki is only practical for sparse Hamiltonians. Trotter-Suzuki is a deterministic compiler but it was recently shown that randomised compiling offers lower overheads. Here we present and analyse a randomised compiler for Hamiltonian simulation where gate probabilities are proportional to the strength of a corresponding term in the Hamiltonian. This approach requires a circuit size independent of $L$ and $\\Lambda$, but instead depending on $\\lambda$ the absolute sum of Hamiltonian strengths (the $\\ell_1$ norm). Therefore, it is especially suited to electronic structure Hamiltonians relevant to quantum chemistry. Considering propane, carbon dioxide and ethane, we observe speed-ups compared to standard Trotter-Suzuki of between $306\\times$ and $1591\\times$ for physically significant simulation times at precision $10^{-3}$. Performing phase estimation at chemical accuracy, we report that the savings are similar.","authors":"Earl Campbell"},"1904.01502":{"title":"Quantum advantage with noisy shallow circuits in 3D","abstract":"Prior work has shown that there exists a relation problem which can be solved with certainty by a constant-depth quantum circuit composed of geometrically local gates in two dimensions, but cannot be solved with high probability by any classical constant depth circuit composed of bounded fan-in gates. Here we provide two extensions of this result. Firstly, we show that a separation in computational power persists even when the constant-depth quantum circuit is restricted to geometrically local gates in one dimension. The corresponding quantum algorithm is the simplest we know of which achieves a quantum advantage of this type. It may also be more practical for future implementations. Our second, main result, is that a separation persists even if the shallow quantum circuit is corrupted by noise. We construct a relation problem which can be solved with near certainty using a noisy constant-depth quantum circuit composed of geometrically local gates in three dimensions, provided the noise rate is below a certain constant threshold value. On the other hand, the problem cannot be solved with high probability by a noise-free classical circuit of constant depth. A key component of the proof is a quantum error-correcting code which admits constant-depth logical Clifford gates and single-shot logical state preparation. We show that the surface code meets these criteria. To this end, we provide a protocol for single-shot logical state preparation in the surface code which may be of independent interest.","authors":"Sergey Bravyi, David Gosset, Robert Koenig, Marco Tomamichel"},"1904.02260":{"title":"Contextuality Test of the Nonclassicality of Variational Quantum Eigensolvers","abstract":"Contextuality is an indicator of non-classicality, and a resource for various quantum procedures. In this paper, we use contextuality to evaluate the variational quantum eigensolver (VQE), one of the most promising tools for near-term quantum simulation. We present an efficiently computable test to determine whether or not the objective function for a VQE procedure is contextual. We apply this test to evaluate the contextuality of experimental implementations of VQE, and determine that several, but not all, fail this test of quantumness.","authors":"William M. Kirby, Peter J. Love"},"1906.02700":{"title":"Quantum Approximate Optimization of the Long-Range Ising Model with a Trapped-Ion Quantum Simulator","abstract":"Quantum computers and simulators may offer significant advantages over their classical counterparts, providing insights into quantum many-body systems and possibly improving performance for solving exponentially hard problems, such as optimization and satisfiability. Here we report the implementation of a low-depth Quantum Approximate Optimization Algorithm (QAOA) using an analog quantum simulator. We estimate the ground state energy of the Transverse Field Ising Model with long-range interactions with tunable range and we optimize the corresponding combinatorial classical problem by sampling the QAOA output with high-fidelity, single-shot individual qubit measurements. We execute the algorithm with both an exhaustive search and closed-loop optimization of the variational parameters, approximating the ground state energy with up to 40 trapped-ion qubits. We benchmark the experiment with bootstrapping heuristic methods scaling polynomially with the system size. We observe, in agreement with numerics, that the QAOA performance does not degrade significantly as we scale up the system size, and that the runtime is approximately independent from the number of qubits. We finally give a comprehensive analysis of the errors occurring in our system, a crucial step in the path forward towards the application of the QAOA to more general problem instances.","authors":"G. Pagano, A. Bapat, P. Becker, K. S. Collins, A. De, P. W. Hess, H. B. Kaplan, A. Kyprianidis, W. L. Tan, C. Baldwin, L. T. Brady, A. Deshpande, F. Liu, S. Jordan, A. V. Gorshkov, C. Monroe"},"1906.08948":{"title":"Quantum Annealing: a journey through Digitalization, Control, and hybrid Quantum Variational schemes","abstract":"We establish and discuss a number of connections between a digitized version of Quantum Annealing (QA) with the Quantum Approximate Optimization Algorithm (QAOA) introduced by Farhi et al. (arXiv:1411.4028) as an alternative hybrid quantum-classical variational scheme for quantum-state preparation and optimization. We introduce a technique that allows to prove, for instance, a rigorous bound concerning the performance of QAOA for MaxCut on a $2$-regular graph, equivalent to an unfrustrated antiferromagnetic Ising chain. The bound shows that the optimal variational error of a depth-$\\mathrm{P}$ quantum circuit has to satisfy $\\epsilon^\\mathrm{res}_{\\mathrm{P}}\\ge (2\\mathrm{P}+2)^{-1}$. In a separate work (Mbeng et al., arXiv:1911.12259) we have explicitly shown, exploiting a Jordan-Wigner transformation, that among the $2^{\\mathrm{P}}$ degenerate variational minima which can be found for this problem, all strictly satisfying the equality $\\epsilon^\\mathrm{res}_{\\mathrm{P}}=(2\\mathrm{P}+2)^{-1}$, one can construct a special {\\em regular} optimal solution, which is computationally optimal and does not require any prior knowledge about the spectral gap. We explicitly demonstrate here that such a schedule is adiabatic, in a digitized sense, and can therefore be interpreted as an optimized digitized-QA protocol. We also discuss and compare our bound on the residual energy to well-known results on the Kibble-Zurek mechanism behind a continuous-time QA. These findings help elucidating the intimate relation between digitized-QA, QAOA, and optimal Quantum Control.","authors":"Glen Bigan Mbeng, Rosario Fazio, Giuseppe Santoro"},"1908.07353":{"title":"A Hierarchy of Anyon Models Realised by Twists in Stacked Surface Codes","abstract":"Braiding defects in topological stabiliser codes can be used to fault-tolerantly implement logical operations. Twists are defects corresponding to the end-points of domain walls and are associated with symmetries of the anyon model of the code. We consider twists in multiple copies of the 2d surface code and identify necessary and sufficient conditions for considering these twists as anyons: namely that they must be self-inverse and that all charges which can be localised by the twist must be invariant under its associated symmetry. If both of these conditions are satisfied the twist and its set of localisable anyonic charges reproduce the behaviour of an anyonic model belonging to a hierarchy which generalises the Ising anyons. We show that the braiding of these twists results in either (tensor products of) the S gate or (tensor products of) the CZ gate. We also show that for any number of copies of the 2d surface code the application of H gates within a copy and CNOT gates between copies is sufficient to generate all possible twists.","authors":"T. R. Scruby, D. E. Browne"},"1908.09959":{"title":"The Overlap Gap Property in Principal Submatrix Recovery","abstract":"We study support recovery for a $k \\times k$ principal submatrix with elevated mean $\\lambda/N$, hidden in an $N\\times N$ symmetric mean zero Gaussian matrix. Here $\\lambda&gt;0$ is a universal constant, and we assume $k = N \\rho$ for some constant $\\rho \\in (0,1)$. We establish that {there exists a constant $C&gt;0$ such that} the MLE recovers a constant proportion of the hidden submatrix if $\\lambda {\\geq C} \\sqrt{\\frac{1}{\\rho} \\log \\frac{1}{\\rho}}$, {while such recovery is information theoretically impossible if $\\lambda = o( \\sqrt{\\frac{1}{\\rho} \\log \\frac{1}{\\rho}} )$}. The MLE is computationally intractable in general, and in fact, for $\\rho&gt;0$ sufficiently small, this problem is conjectured to exhibit a \\emph{statistical-computational gap}. To provide rigorous evidence for this, we study the likelihood landscape for this problem, and establish that for some $\\varepsilon&gt;0$ and $\\sqrt{\\frac{1}{\\rho} \\log \\frac{1}{\\rho} } \\ll \\lambda \\ll \\frac{1}{\\rho^{1/2 + \\varepsilon}}$, the problem exhibits a variant of the \\emph{Overlap-Gap-Property (OGP)}. As a direct consequence, we establish that a family of local MCMC based algorithms do not achieve optimal recovery. Finally, we establish that for $\\lambda &gt; 1/\\rho$, a simple spectral method recovers a constant proportion of the hidden submatrix.","authors":"David Gamarnik, Aukosh Jagannath, Subhabrata Sen"},"1910.08980":{"title":"Obstacles to State Preparation and Variational Optimization from Symmetry Protection","abstract":"Local Hamiltonians with topological quantum order exhibit highly entangled ground states that cannot be prepared by shallow quantum circuits. Here, we show that this property may extend to all low-energy states in the presence of an on-site $\\mathbb{Z}_2$ symmetry. This proves a version of the No Low-Energy Trivial States (NLTS) conjecture for a family of local Hamiltonians with symmetry protected topological order. A surprising consequence of this result is that the Goemans-Williamson algorithm outperforms the Quantum Approximate Optimization Algorithm (QAOA) for certain instances of MaxCut, at any constant level. We argue that the locality and symmetry of QAOA severely limits its performance. To overcome these limitations, we propose a non-local version of QAOA, and give numerical evidence that it significantly outperforms standard QAOA for frustrated Ising models on random 3-regular graphs.","authors":"Sergey Bravyi, Alexander Kliesch, Robert Koenig, Eugene Tang"},"1912.08854":{"title":"A Theory of Trotter Error","abstract":"The Lie-Trotter formula, together with its higher-order generalizations, provides a direct approach to decomposing the exponential of a sum of operators. Despite significant effort, the error scaling of such product formulas remains poorly understood. We develop a theory of Trotter error that overcomes the limitations of prior approaches based on truncating the Baker-Campbell-Hausdorff expansion. Our analysis directly exploits the commutativity of operator summands, producing tighter error bounds for both real- and imaginary-time evolutions. Whereas previous work achieves similar goals for systems with geometric locality or Lie-algebraic structure, our approach holds in general. We give a host of improved algorithms for digital quantum simulation and quantum Monte Carlo methods, including simulations of second-quantized plane-wave electronic structure, $k$-local Hamiltonians, rapidly decaying power-law interactions, clustered Hamiltonians, the transverse field Ising model, and quantum ferromagnets, nearly matching or even outperforming the best previous results. We obtain further speedups using the fact that product formulas can preserve the locality of the simulated system. Specifically, we show that local observables can be simulated with complexity independent of the system size for power-law interacting systems, which implies a Lieb-Robinson bound as a byproduct. Our analysis reproduces known tight bounds for first- and second-order formulas. Our higher-order bound overestimates the complexity of simulating a one-dimensional Heisenberg model with an even-odd ordering of terms by only a factor of $5$, and is close to tight for power-law interactions and other orderings of terms. This suggests that our theory can accurately characterize Trotter error in terms of both asymptotic scaling and constant prefactor.","authors":"Andrew M. Childs, Yuan Su, Minh C. Tran, Nathan Wiebe, Shuchen Zhu"},"2002.05693":{"title":"Classical Simulation of Noncontextual Pauli Hamiltonians","abstract":"Noncontextual Pauli Hamiltonians decompose into sets of Pauli terms to which joint values may be assigned without contradiction. We construct a quasi-quantized model for noncontextual Pauli Hamiltonians. Using this model, we give an algorithm to classically simulate noncontextual VQE. We also use the model to show that the noncontextual Hamiltonian problem is NP-complete. Finally, we explore the applicability of our quasi-quantized model as an approximate simulation tool for contextual Hamiltonians. These results support the notion of noncontextuality as classicality in near-term quantum algorithms.","authors":"William M. Kirby, Peter J. Love"},"2002.08953":{"title":"Predicting Many Properties of a Quantum System from Very Few Measurements","abstract":"Predicting properties of complex, large-scale quantum systems is essential for developing quantum technologies. We present an efficient method for constructing an approximate classical description of a quantum state using very few measurements of the state. This description, called a classical shadow, can be used to predict many different properties: order $\\log M$ measurements suffice to accurately predict $M$ different functions of the state with high success probability. The number of measurements is independent of the system size, and saturates information-theoretic lower bounds. Moreover, target properties to predict can be selected after the measurements are completed. We support our theoretical findings with extensive numerical experiments. We apply classical shadows to predict quantum fidelities, entanglement entropies, two-point correlation functions, expectation values of local observables, and the energy variance of many-body local Hamiltonians. The numerical results highlight the advantages of classical shadows relative to previously known methods.","authors":"Hsin-Yuan Huang, Richard Kueng, John Preskill"},"2002.11649":{"title":"Efficient phase-factor evaluation in quantum signal processing","abstract":"Quantum signal processing (QSP) is a powerful quantum algorithm to exactly implement matrix polynomials on quantum computers. Asymptotic analysis of quantum algorithms based on QSP has shown that asymptotically optimal results can in principle be obtained for a range of tasks, such as Hamiltonian simulation and the quantum linear system problem. A further benefit of QSP is that it uses a minimal number of ancilla qubits, which facilitates its implementation on near-to-intermediate term quantum architectures. However, there is so far no classically stable algorithm allowing computation of the phase factors that are needed to build QSP circuits. Existing methods require the usage of variable precision arithmetic and can only be applied to polynomials of relatively low degree. We present here an optimization based method that can accurately compute the phase factors using standard double precision arithmetic operations. We demonstrate the performance of this approach with applications to Hamiltonian simulation, eigenvalue filtering, and the quantum linear system problems. Our numerical results show that the optimization algorithm can find phase factors to accurately approximate polynomials of degree larger than $10,000$ with error below $10^{-12}$.","authors":"Yulong Dong, Xiang Meng, K. Birgitta Whaley, Lin Lin"},"2003.07419":{"title":"Polynomial scaling of QAOA for ground-state preparation of the fully-connected p-spin ferromagnet","abstract":"We show that the quantum approximate optimization algorithm (QAOA) can construct with polynomially scaling resources the ground state of the fully-connected p-spin Ising ferromagnet, a problem that notoriously poses severe difficulties to a Quantum Annealing (QA) approach, due to the exponentially small gaps encountered at first-order phase transition for ${\\rm p} \\ge 3$. For a target ground state at arbitrary transverse field, we find that an appropriate QAOA parameter initialization is necessary to achieve a good performance of the algorithm when the number of variational parameters $2{\\rm P}$ is much smaller than the system size ${\\rm N}$, because of the large number of sub-optimal local minima. Instead, when ${\\rm P}$ exceeds a critical value ${\\rm P}^*_{\\rm N} \\propto {\\rm N}$, the structure of the parameter space simplifies, as all minima become degenerate. This allows to achieve the ground state with perfect fidelity with a number of parameters scaling extensively with ${\\rm N}$, and with resources scaling polynomially with ${\\rm N}$.","authors":"Matteo M. Wauters, Glen Bigan Mbeng, Giuseppe E. Santoro"},"2004.11568":{"title":"Efficient Algorithms for Approximating Quantum Partition Functions","abstract":"We establish a polynomial-time approximation algorithm for partition functions of quantum spin models at high temperature. Our algorithm is based on the quantum cluster expansion of Neto\\v{c}n\\'y and Redig and the cluster expansion approach to designing algorithms due to Helmuth, Perkins, and Regts. Similar results have previously been obtained by related methods, and our main contribution is a simple and slightly sharper analysis for the case of pairwise interactions on bounded-degree graphs.","authors":"Ryan L. Mann, Tyler Helmuth"},"2005.02421":{"title":"Spoofing Linear Cross-Entropy Benchmarking in Shallow Quantum Circuits","abstract":"The linear cross-entropy benchmark (Linear XEB) has been used as a test for procedures simulating quantum circuits. Given a quantum circuit $C$ with $n$ inputs and outputs and purported simulator whose output is distributed according to a distribution $p$ over $\\{0,1\\}^n$, the linear XEB fidelity of the simulator is $\\mathcal{F}_{C}(p) = 2^n \\mathbb{E}_{x \\sim p} q_C(x) -1$ where $q_C(x)$ is the probability that $x$ is output from the distribution $C|0^n\\rangle$. A trivial simulator (e.g., the uniform distribution) satisfies $\\mathcal{F}_C(p)=0$, while Google's noisy quantum simulation of a 53 qubit circuit $C$ achieved a fidelity value of $(2.24\\pm0.21)\\times10^{-3}$ (Arute et. al., Nature'19). In this work we give a classical randomized algorithm that for a given circuit $C$ of depth $d$ with Haar random 2-qubit gates achieves in expectation a fidelity value of $\\Omega(\\tfrac{n}{L} \\cdot 15^{-d})$ in running time $\\textsf{poly}(n,2^L)$. Here $L$ is the size of the \\emph{light cone} of $C$: the maximum number of input bits that each output bit depends on. In particular, we obtain a polynomial-time algorithm that achieves large fidelity of $\\omega(1)$ for depth $O(\\sqrt{\\log n})$ two-dimensional circuits. To our knowledge, this is the first such result for two dimensional circuits of super-constant depth. Our results can be considered as an evidence that fooling the linear XEB test might be easier than achieving a full simulation of the quantum circuit.","authors":"Boaz Barak, Chi-Ning Chou, Xun Gao"},"2005.05832":{"title":"Creative Quantum Computing: Inverse FFT, Sound Synthesis, Adaptive Sequencing and Musical Composition","abstract":"Quantum computing is emerging as an alternative computing technology, which is built on the principles of subatomic physics. In spite of continuing progress in developing increasingly more sophisticated hardware and software, access to quantum computing still requires specialist expertise that is largely confined to research laboratories. Moreover, the target applications for these developments remain primarily scientific. This chapter introduces research aimed at improving this scenario. Our research is aimed at extending the range of applications of quantum computing towards the arts and creative applications, music being our point of departure. This chapter reports on initial outcomes, whereby quantum information processing controls an inverse Fast Fourier Transform (FFT) sound synthesizer and an adaptive musical sequencer. A composition called Zeno is presented to illustrate a practical real-world application.","authors":"Eduardo R. Miranda"},"2005.08747":{"title":"The Quantum Approximate Optimization Algorithm Needs to See the Whole Graph: Worst Case Examples","abstract":"The Quantum Approximate Optimization Algorithm can be applied to search problems on graphs with a cost function that is a sum of terms corresponding to the edges. When conjugating an edge term, the QAOA unitary at depth p produces an operator that depends only on the subgraph consisting of edges that are at most p away from the edge in question. On random d-regular graphs, with d fixed and with p a small constant time log n, these neighborhoods are almost all trees and so the performance of the QAOA is determined only by how it acts on an edge in the middle of tree. Both bipartite random d-regular graphs and general random d-regular graphs locally are trees so the QAOA's performance is the same on these two ensembles. Using this we can show that the QAOA with $(d-1)^{2p} &lt; n^A$ for any $A&lt;1$, can only achieve an approximation ratio of 1/2 for Max-Cut on bipartite random d-regular graphs for d large. For Maximum Independent Set, in the same setting, the best approximation ratio is a d-dependent constant that goes to 0 as d gets big.","authors":"Edward Farhi, David Gamarnik, Sam Gutmann"},"2005.11011":{"title":"Using models to improve optimizers for variational quantum algorithms","abstract":"Variational quantum algorithms are a leading candidate for early applications on noisy intermediate-scale quantum computers. These algorithms depend on a classical optimization outer-loop that minimizes some function of a parameterized quantum circuit. In practice, finite sampling error and gate errors make this a stochastic optimization with unique challenges that must be addressed at the level of the optimizer. The sharp trade-off between precision and sampling time in conjunction with experimental constraints necessitates the development of new optimization strategies to minimize overall wall clock time in this setting. In this work, we introduce two optimization methods and numerically compare their performance with common methods in use today. The methods are surrogate model-based algorithms designed to improve reuse of collected data. They do so by utilizing a least-squares quadratic fit of sampled function values within a moving trusted region to estimate the gradient or a policy gradient. To make fair comparisons between optimization methods, we develop experimentally relevant cost models designed to balance efficiency in testing and accuracy with respect to cloud quantum computing systems. The results here underscore the need to both use relevant cost models and optimize hyperparameters of existing optimization methods for competitive performance. The methods introduced here have several practical advantages in realistic experimental settings, and we have used one of them successfully in a separately published experiment on Google's Sycamore device.","authors":"Kevin J. Sung, Jiahao Yao, Matthew P. Harrigan, Nicholas C. Rubin, Zhang Jiang, Lin Lin, Ryan Babbush, Jarrod R. McClean"},"2006.09350":{"title":"Minimizing estimation runtime on noisy quantum computers","abstract":"The number of measurements demanded by hybrid quantum-classical algorithms such as the variational quantum eigensolver (VQE) is prohibitively high for many problems of practical value. For such problems, realizing quantum advantage will require methods which dramatically reduce this cost. Previous quantum algorithms that reduce the measurement cost (e.g. quantum amplitude and phase estimation) require error rates that are too low for near-term implementation. Here we propose methods that take advantage of the available quantum coherence to maximally enhance the power of sampling on noisy quantum devices, reducing measurement number and runtime compared to the standard sampling method of the variational quantum eigensolver (VQE). Our scheme derives inspiration from quantum metrology, phase estimation, and the more recent \"alpha-VQE\" proposal, arriving at a general formulation that is robust to error and does not require ancilla qubits. The central object of this method is what we call the \"engineered likelihood function\" (ELF), used for carrying out Bayesian inference. We show how the ELF formalism enhances the rate of information gain in sampling as the physical hardware transitions from the regime of noisy intermediate-scale quantum computers into that of quantum error corrected ones. This technique speeds up a central component of many quantum algorithms, with applications including chemistry, materials, finance, and beyond. Similar to VQE, we expect small-scale implementations to be realizable on today's quantum devices.","authors":"Guoming Wang, Dax Enshan Koh, Peter D. Johnson, Yudong Cao"},"2008.00466":{"title":"Complexity continuum within Ising formulation of NP problems","abstract":"A promising approach to achieve computational supremacy over the classical von Neumann architecture explores classical and quantum hardware as Ising machines. The minimisation of the Ising Hamiltonian is known to be NP-hard problem for certain interaction matrix classes, yet not all problem instances are equivalently hard to optimise. We propose to identify computationally simple instances with an `optimisation simplicity criterion'. Such optimisation simplicity can be found for a wide range of models from spin glasses to k-regular maximum cut problems. Many optical, photonic, and electronic systems are neuromorphic architectures that can naturally operate to optimise problems satisfying this criterion and, therefore, such problems are often chosen to illustrate the computational advantages of new Ising machines. We further probe an intermediate complexity for sparse and dense models by analysing circulant coupling matrices, that can be `rewired' to introduce greater complexity. A compelling approach for distinguishing easy and hard instances within the same NP-hard class of problems can be a starting point in developing a standardised procedure for the performance evaluation of emerging physical simulators and physics-inspired algorithms.","authors":"Kirill P. Kalinin, Natalia G. Berloff"},"2008.04628":{"title":"Bolometer operating at the threshold for circuit quantum electrodynamics","abstract":"Radiation sensors based on the heating effect of the absorbed radiation are typically relatively simple to operate and flexible in terms of the input frequency. Consequently, they are widely applied, for example, in gas detection, security, THz imaging, astrophysical observations, and medical applications. A new spectrum of important applications is currently emerging from quantum technology and especially from electrical circuits behaving quantum mechanically. This circuit quantum electrodynamics (cQED) has given rise to unprecedented single-photon detectors and a quantum computer supreme to the classical supercomputers in a certain task. Thermal sensors are appealing in enhancing these devices since they are not plagued by quantum noise and are smaller, simpler, and consume about six orders of magnitude less power than the commonly used traveling-wave parametric amplifiers. However, despite great progress in the speed and noise levels of thermal sensors, no bolometer to date has proven fast and sensitive enough to provide advantages in cQED. Here, we experimentally demonstrate a bolometer surpassing this threshold with a noise equivalent power of $30\\, \\rm{zW}/\\sqrt{\\rm{Hz}}$ on par with the current record while providing two-orders of magnitude shorter thermal time constant of 500 ns. Importantly, both of these characteristic numbers have been measured directly from the same device, which implies a faithful estimation of the calorimetric energy resolution of a single 30-GHz photon. These improvements stem from the utilization of a graphene monolayer as the active material with extremely low specific heat. The minimum demonstrated time constant of 200 ns falls greatly below the state-of-the-art dephasing times of roughly 100 {\\mu}s for superconducting qubits and meets the timescales of contemporary readout schemes thus enabling the utilization of thermal detectors in cQED.","authors":"R. Kokkoniemi, J. -P. Girard, D. Hazra, A. Laitinen, J. Govenius, R. E. Lake, I. Sallinen, V. Vesterinen, P. Hakonen, M. Möttönen"},"2009.07450":{"title":"On the Hardness of Detecting Macroscopic Superpositions","abstract":"When is decoherence \"effectively irreversible\"? Here we examine this central question of quantum foundations using the tools of quantum computational complexity. We prove that, if one had a quantum circuit to determine if a system was in an equal superposition of two orthogonal states (for example, the $|$Alive$\\rangle$ and $|$Dead$\\rangle$ states of Schr\\\"{o}dinger's cat), then with only a slightly larger circuit, one could also $\\mathit{swap}$ the two states (e.g., bring a dead cat back to life). In other words, observing interference between the $|$Alive$\\rangle$and $|$Dead$\\rangle$ states is a \"necromancy-hard\" problem, technologically infeasible in any world where death is permanent. As for the converse statement (i.e., ability to swap implies ability to detect interference), we show that it holds modulo a single exception, involving unitaries that (for example) map $|$Alive$\\rangle$ to $|$Dead$\\rangle$ but $|$Dead$\\rangle$ to -$|$Alive$\\rangle$. We also show that these statements are robust---i.e., even a $\\mathit{partial}$ ability to observe interference implies partial swapping ability, and vice versa. Finally, without relying on any unproved complexity conjectures, we show that all of these results are quantitatively tight. Our results have possible implications for the state dependence of observables in quantum gravity, the subject that originally motivated this study.","authors":"Scott Aaronson, Yosi Atia, Leonard Susskind"},"2009.11170":{"title":"Explicit construction of exact unitary designs","abstract":"The purpose of this paper is to give explicit constructions of unitary $t$-designs in the unitary group $U(d)$ for all $t$ and $d$. It seems that the explicit constructions were so far known only for very special cases. Here explicit construction means that the entries of the unitary matrices are given by the values of elementary functions at the root of some given polynomials. We will discuss what are the best such unitary $4$-designs in $U(4)$ obtained by these methods. Indeed we give an inductive construction of designs on compact groups by using Gelfand pairs $(G,K)$. Note that $(U(n),U(m) \\times U(n-m))$ is a Gelfand pair. By using the zonal spherical functions for $(G,K)$, we can construct designs on $G$ from designs on $K$. We remark that our proofs use the representation theory of compact groups crucially. We also remark that this method can be applied to the orthogonal groups $O(d)$, and thus provides another explicit construction of spherical $t$-designs on the $d$ dimensional sphere $S^{d-1}$ by the induction on $d$.","authors":"Eiichi Bannai, Yoshifumi Nakata, Takayuki Okuda, Da Zhao"},"2009.12472":{"title":"How will quantum computers provide an industrially relevant computational advantage in quantum chemistry?","abstract":"Numerous reports claim that quantum advantage, which should emerge as a direct consequence of the advent of quantum computers, will herald a new era of chemical research because it will enable scientists to perform the kinds of quantum chemical simulations that have not been possible before. Such simulations on quantum computers, promising a significantly greater accuracy and speed, are projected to exert a great impact on the way we can probe reality, predict the outcomes of chemical experiments, and even drive design of drugs, catalysts, and materials. In this work we review the current status of quantum hardware and algorithm theory and examine whether such popular claims about quantum advantage are really going to be transformative. We go over subtle complications of quantum chemical research that tend to be overlooked in discussions involving quantum computers. We estimate quantum computer resources that will be required for performing calculations on quantum computers with chemical accuracy for several types of molecules. In particular, we directly compare the resources and timings associated with classical and quantum computers for the molecules H$_2$ for increasing basis set sizes, and Cr$_2$ for a variety of complete active spaces (CAS) within the scope of the CASCI and CASSCF methods. The results obtained for the chromium dimer enable us to estimate the size of the active space at which computations of non-dynamic correlation on a quantum computer should take less time than analogous computations on a classical computer. Using this result, we speculate on the types of chemical applications for which the use of quantum computers would be both beneficial and relevant to industrial applications in the short term.","authors":"V. E. Elfving, B. W. Broer, M. Webber, J. Gavartin, M. D. Halls, K. P. Lorton, A. Bochevarov"},"2012.02022":{"title":"Determining QMC simulability with geometric phases","abstract":"Although stoquastic Hamiltonians are known to be simulable via sign-problem-free quantum Monte Carlo (QMC) techniques, the non-stoquasticity of a Hamiltonian does not necessarily imply the existence of a QMC sign problem. We give a sufficient and necessary condition for the QMC-simulability of Hamiltonians in a fixed basis in terms of geometric phases associated with the chordless cycles of the weighted graphs whose adjacency matrices are the Hamiltonians. We use our findings to provide a construction for non-stoquastic, yet sign-problem-free and hence QMC-simulable, quantum many-body models. We also demonstrate why the simulation of truly sign-problematic models using the QMC weights of the stoquasticized Hamiltonian is generally sub-optimal. We offer a superior alternative.","authors":"Itay Hen"},"2012.03924":{"title":"Generation of High-Resolution Handwritten Digits with an Ion-Trap Quantum Computer","abstract":"Generating high-quality data (e.g. images or video) is one of the most exciting and challenging frontiers in unsupervised machine learning. Utilizing quantum computers in such tasks to potentially enhance conventional machine learning algorithms has emerged as a promising application, but poses big challenges due to the limited number of qubits and the level of gate noise in available devices. In this work, we provide the first practical and experimental implementation of a quantum-classical generative algorithm capable of generating high-resolution images of handwritten digits with state-of-the-art gate-based quantum computers. In our quantum-assisted machine learning framework, we implement a quantum-circuit based generative model to learn and sample the prior distribution of a Generative Adversarial Network. We introduce a multi-basis technique which leverages the unique possibility of measuring quantum states in different bases, hence enhancing the expressibility of the prior distribution. We train this hybrid algorithm on an ion-trap device based on $^{171}$Yb$^{+}$ ion qubits to generate high-quality images and quantitatively outperform comparable classical Generative Adversarial Networks trained on the popular MNIST data set for handwritten digits.","authors":"Manuel S. Rudolph, Ntwali Bashige Toussaint, Amara Katabarwa, Sonika Johri, Borja Peropadre, Alejandro Perdomo-Ortiz"},"2012.07825":{"title":"Analyzing the Performance of Variational Quantum Factoring on a Superconducting Quantum Processor","abstract":"In the near-term, hybrid quantum-classical algorithms hold great potential for outperforming classical approaches. Understanding how these two computing paradigms work in tandem is critical for identifying areas where such hybrid algorithms could provide a quantum advantage. In this work, we study a QAOA-based quantum optimization algorithm by implementing the Variational Quantum Factoring (VQF) algorithm. We execute experimental demonstrations using a superconducting quantum processor and investigate the trade-off between quantum resources (number of qubits and circuit depth) and the probability that a given biprime is successfully factored. In our experiments, the integers 1099551473989, 3127, and 6557 are factored with 3, 4, and 5 qubits, respectively, using a QAOA ansatz with up to 8 layers and we are able to identify the optimal number of circuit layers for a given instance to maximize success probability. Furthermore, we demonstrate the impact of different noise sources on the performance of QAOA and reveal the coherent error caused by the residual ZZ-coupling between qubits as a dominant source of error in the superconducting quantum processor.","authors":"Amir H. Karamlou, William A. Simon, Amara Katabarwa, Travis L. Scholten, Borja Peropadre, Yudong Cao"}}